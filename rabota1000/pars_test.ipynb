{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from fake_useragent import FakeUserAgent\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подгрузка данных из файла окружения\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Обращения\n",
    "# config[hh_api_name]\n",
    "# config[hh_api_Client_ID]\n",
    "# config[hh_api_Client_Secret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные регулярные выражения для проекта\n",
    "re_vacancy_id_hh = r'\\/vacancy\\/(\\d+)\\?'\n",
    "re_vacancy_id_rabota = r'\\/vacancy\\/(\\d+)'\n",
    "re_vacancy_id_finder = r'\\/vacancies\\/(\\d+)'\n",
    "re_vacancy_id_zarplata = r'\\/vacancy\\/card\\/id(\\d+)'\n",
    "\n",
    "# re.search(re_vacancy_id, string).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rabota1000_Parser:\n",
    "    # Класс для парсинга вакансий с ресурса Rabota1000.ru\n",
    "    \n",
    "\n",
    "    def __init__(self, city:str='russia'):\n",
    "        self.max_page_count = 5\n",
    "        self.basic_url = 'https://rabota1000.ru/russia/'\n",
    "        self.vac_name_list = []\n",
    "        self.vac_name_list = self.get_vac_name_into_file('vacancy_name_to_pars.txt')\n",
    "        \n",
    "        ua = FakeUserAgent()\n",
    "        headers = {'user-agent':ua.random}\n",
    "\n",
    "        self._pars()\n",
    "\n",
    "    def _pars(self):\n",
    "        if not os.path.exists('pars_link.csv'):\n",
    "            with open('pars_link.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "                names = ['vac_name', 'link', 'source', 'vac_id']\n",
    "                file_writer = csv.DictWriter(csv_file, delimiter = \",\", lineterminator=\"\\r\", fieldnames=names)\n",
    "                file_writer.writeheader()\n",
    "\n",
    "            for vac_name in self.vac_name_list:\n",
    "                print(vac_name)\n",
    "                try:\n",
    "                    used_url = self.basic_url + vac_name + \"/\"\n",
    "                    response = requests.get(used_url)\n",
    "                    response.raise_for_status()\n",
    "                    for i in range(1, self.max_page_count+1):\n",
    "                        print(i, end=' ')\n",
    "                        used_url = f'{self.basic_url}{vac_name}?p={i}'\n",
    "                        page = requests.get(used_url)\n",
    "                        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "                        # 20 ссылок на одной странице\n",
    "                        links = [requests.get(link['href']).url for link in soup.findAll('a', attrs={'@click':'vacancyLinkClickHandler'})]\n",
    "                        sources = [source.text for source in soup.findAll('span', attrs={'class':'text-sky-600'})]\n",
    "\n",
    "                        links_to_save = [[vac_name, link, source] for link, source in zip(links, sources)]\n",
    "\n",
    "                        with open('pars_link.csv', 'a', newline='', encoding='utf-8') as csv_file:\n",
    "                            writer = csv.writer(csv_file)\n",
    "                            writer.writerows(links_to_save)\n",
    "                            \n",
    "                except HTTPError as exc:\n",
    "                    code = exc.response.status_code\n",
    "                    print(code)\n",
    "                print()\n",
    "\n",
    "        links_for_processing = []\n",
    "        with open('pars_link.csv', 'r', encoding='utf-8') as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            labels = next(reader, None)\n",
    "            for row in reader:\n",
    "                links_for_processing.append(dict(zip(labels, row)))\n",
    "        \n",
    "        for item in links_for_processing:\n",
    "            if item['source'] == 'hh.ru':\n",
    "                item['vac_id'] = re.search(re_vacancy_id_hh, item['link']).group(1)\n",
    "            elif item['source'] == 'finder.vc':\n",
    "                item['vac_id'] = re.search(re_vacancy_id_finder, item['link']).group(1)\n",
    "            elif item['source'] == 'zarplata.ru':\n",
    "                item['vac_id'] = re.search(re_vacancy_id_zarplata, item['link']).group(1)\n",
    "            else:\n",
    "                item['vac_id'] = re.search(re_vacancy_id, item['link']).group(1)\n",
    "\n",
    "        pre_resualt = []\n",
    "        for link in links_for_processing:\n",
    "            if link['source'] == 'hh.ru':\n",
    "                pre_resualt.append(self._pars_url_hh(link['vac_id']))\n",
    "            elif link['source'] == 'zarplata.ru':\n",
    "                pre_resualt.append(self._pars_url_zarplata(link['vac_id']))\n",
    "            else:\n",
    "                pre_resualt.append(self._pars_url_other(link['vac_id']))\n",
    "\n",
    "    def get_vac_name_into_file(self, vac_file_path:str)->list:\n",
    "        vac_name_list = []\n",
    "        with open(vac_file_path, mode='r', encoding=\"utf-8\") as file_vac:\n",
    "            vac_name_list = list(map(lambda x: x.lower().replace('\\n', '').replace(' ','+'), file_vac.readlines()))\n",
    "\n",
    "        return vac_name_list\n",
    "\n",
    "    def _pars_url_hh(self, id)->dict:\n",
    "        res = {}\n",
    "        data = requests.get(f'https://api.hh.ru/vacancies/{id}').json()\n",
    "        res['vac_link'] = f'https://hh.ru/vacancy/{id}' # Ссылка\n",
    "        res['name'] = data['name']                      # Название\n",
    "        res['city'] = data['area']['name']              # Город\n",
    "        res['company'] = data['employer']['name']       # Назвнание компании публикующей вакансию\n",
    "        res['experience'] = data['experience']['name']  # Опыт работы (нет замены на jun mid и sin)\n",
    "        res['schedule'] = data['schedule']['name']      # Тип работы (офис/удаленка и тд)\n",
    "        res['employment'] = data['employment']['name']  # График работы\n",
    "        res['skills'] = data['key_skills']              # Ключевые навыки\n",
    "        res['description'] = data['description']        # Полное описание (html теги не убраны)\n",
    "        if data['salary'] == None: \n",
    "            res['salary'] = 'Договорная'                # Если ЗП не указано то пишем договорная\n",
    "        else:\n",
    "            res['salary'] = data['salary']              # Если есть то берем как есть\n",
    "        res['time'] = data['published_at']              # Дата и время публикации\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def _pars_url_zarplata(self, id)->dict:\n",
    "        res = {}\n",
    "        data = requests.get(f'https://api.zarplata.ru/vacancies/{id}').json()\n",
    "        res['vac_link'] = f'https://www.zarplata.ru/vacancy/card/id{id}' # Ссылка\n",
    "        res['name'] = data['name']                      # Название\n",
    "        res['city'] = data['area']['name']              # Город\n",
    "        res['company'] = data['employer']['name']       # Назвнание компании публикующей вакансию\n",
    "        res['experience'] = data['experience']['name']  # Опыт работы (нет замены на jun mid и sin)\n",
    "        res['schedule'] = data['schedule']['name']      # Тип работы (офис/удаленка и тд)\n",
    "        res['employment'] = data['employment']['name']  # График работы\n",
    "        res['skills'] = data['key_skills']              # Ключевые навыки\n",
    "        res['description'] = data['description']        # Полное описание (html теги не убраны)\n",
    "        if data['salary'] == None: \n",
    "            res['salary'] = 'Договорная'                # Если ЗП не указано то пишем договорная\n",
    "        else:\n",
    "            res['salary'] = data['salary']              # Если есть то берем как есть\n",
    "        res['time'] = data['published_at']\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def _pars_url_other(self, id)->dict:\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "parser = Rabota1000_Parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо достать в результате\n",
    "\n",
    "- Название вакансии +\n",
    "- Название компании +\n",
    "- З/п +\n",
    "- Формат работы +\n",
    "- Тип занятости +\n",
    "- Навыки (Если можно достать отдельно) +\n",
    "- Описание вакансии (если есть требования или навыки - то отлично, берем их) +\n",
    "- Время публикации +\n",
    "- Ссылка на вакансию тоже должна быть у нас +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vac_link https://www.zarplata.ru/vacancy/card/id87774221\n",
      "name Курьер\n",
      "city Москва\n",
      "company Рултек\n",
      "experience Нет опыта\n",
      "schedule Полный день\n",
      "employment Полная занятость\n",
      "skills [{'name': 'Мобильность'}, {'name': 'Пользователь ПК'}]\n",
      "description <p><strong>Требуется курьер </strong>на доставку документов</p> <p> </p> <p><strong>Условия:</strong></p> <p>Доставка документов</p> <p>Проезд и мобильная связь оплачивается в полном размере.</p> <p>Зарплата выплачивается регулярно, 2 раза в месяц.</p>\n",
      "salary {'from': 28000, 'to': 35000, 'currency': 'RUR', 'gross': False}\n",
      "time 2023-10-05T12:08:57+0300\n"
     ]
    }
   ],
   "source": [
    "id = 87774221\n",
    "\n",
    "\n",
    "\n",
    "for key, value in res.items():\n",
    "    print(key, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
