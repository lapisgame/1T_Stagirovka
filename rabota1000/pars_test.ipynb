{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "from lxml.etree import tostring as htmlstring\n",
    "import requests\n",
    "import psycopg2 as psy\n",
    "\n",
    "from fake_useragent import FakeUserAgent\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import date, timedelta\n",
    "import json\n",
    "import time\n",
    "\n",
    "import progressbar\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подгрузка данных из файла окружения\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Обращения\n",
    "# config['hh_api_name']\n",
    "# config['hh_api_Client_ID']\n",
    "# config['hh_api_Client_Secret']\n",
    "\n",
    "params = {\n",
    "    'grant_type':'client_credentials',\n",
    "    'client_id':config['hh_api_Client_ID'],\n",
    "    'client_secret':config['hh_api_Client_Secret']\n",
    "}\n",
    "\n",
    "# access_token = json.loads(requests.post(f'https://hh.ru/oauth/token', params=params).content.decode())['access_token']\n",
    "access_token = 'APPLU3MED5SMTSJA70RJ0BNEFQS6DGA6QBRA6N8PCB7BOIJFF05U46CI4A1J2NN9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные регулярные выражения для проекта\n",
    "re_vacancy_id_hh = r'\\/vacancy\\/(\\d+)\\?'\n",
    "re_vacancy_id_rabota = r'\\/vacancy\\/(\\d+)'\n",
    "re_vacancy_id_finder = r'\\/vacancies\\/(\\d+)'\n",
    "re_vacancy_id_zarplata = r'\\/vacancy\\/card\\/id(\\d+)'\n",
    "\n",
    "re_html_tag_remove = r'<[^>]+>'\n",
    "\n",
    "# re.search(re_vacancy_id, string).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data+scientist\n",
      "1 https://rabota1000.ru/vacancy/104770616\n",
      "https://rabota1000.ru/vacancy/103341030\n",
      "https://rabota1000.ru/vacancy/88087645\n",
      "https://rabota1000.ru/vacancy/103698750\n",
      "https://rabota1000.ru/vacancy/101447379\n",
      "https://rabota1000.ru/vacancy/98928217\n",
      "https://rabota1000.ru/vacancy/110167964\n",
      "https://rabota1000.ru/vacancy/105369250\n",
      "https://rabota1000.ru/vacancy/103693182\n",
      "https://rabota1000.ru/vacancy/103706177\n",
      "https://rabota1000.ru/vacancy/103177742\n",
      "https://rabota1000.ru/vacancy/98948136\n",
      "https://rabota1000.ru/vacancy/99892552\n",
      "https://rabota1000.ru/vacancy/110020884\n",
      "https://rabota1000.ru/vacancy/113203965\n",
      "https://rabota1000.ru/vacancy/114054291\n",
      "https://rabota1000.ru/vacancy/87585211\n",
      "https://rabota1000.ru/vacancy/108607355\n",
      "https://rabota1000.ru/vacancy/113995882\n",
      "https://rabota1000.ru/vacancy/94928170\n",
      "2 https://rabota1000.ru/vacancy/105358186\n",
      "https://rabota1000.ru/vacancy/107728714\n",
      "https://rabota1000.ru/vacancy/107705580\n",
      "https://rabota1000.ru/vacancy/106782907\n",
      "https://rabota1000.ru/vacancy/103324760\n",
      "https://rabota1000.ru/vacancy/104136390\n",
      "https://rabota1000.ru/vacancy/103169218\n",
      "https://rabota1000.ru/vacancy/105572305\n",
      "https://rabota1000.ru/vacancy/105576513\n",
      "https://rabota1000.ru/vacancy/108834453\n",
      "https://rabota1000.ru/vacancy/107964935\n",
      "https://rabota1000.ru/vacancy/107970963\n",
      "https://rabota1000.ru/vacancy/88087633\n",
      "https://rabota1000.ru/vacancy/61914562\n",
      "https://rabota1000.ru/vacancy/108633776\n",
      "https://rabota1000.ru/vacancy/90753526\n",
      "https://rabota1000.ru/vacancy/87826846\n",
      "https://rabota1000.ru/vacancy/87826788\n",
      "https://rabota1000.ru/vacancy/106750861\n",
      "https://rabota1000.ru/vacancy/114018507\n",
      "3 https://rabota1000.ru/vacancy/25091466\n",
      "https://rabota1000.ru/vacancy/101160704\n",
      "https://rabota1000.ru/vacancy/107892727\n",
      "https://rabota1000.ru/vacancy/104672577\n",
      "https://rabota1000.ru/vacancy/114724525\n",
      "https://rabota1000.ru/vacancy/114025437\n",
      "https://rabota1000.ru/vacancy/100957325\n",
      "https://rabota1000.ru/vacancy/108842086\n",
      "https://rabota1000.ru/vacancy/78041571\n",
      "https://rabota1000.ru/vacancy/112372307\n",
      "https://rabota1000.ru/vacancy/107027867\n",
      "https://rabota1000.ru/vacancy/108555675\n",
      "https://rabota1000.ru/vacancy/90893874\n",
      "https://rabota1000.ru/vacancy/114031026\n",
      "https://rabota1000.ru/vacancy/110175569\n",
      "https://rabota1000.ru/vacancy/94889537\n",
      "https://rabota1000.ru/vacancy/108790279\n",
      "https://rabota1000.ru/vacancy/104408519\n",
      "https://rabota1000.ru/vacancy/510785\n",
      "https://rabota1000.ru/vacancy/95686551\n",
      "4 https://rabota1000.ru/vacancy/107895375\n",
      "https://rabota1000.ru/vacancy/55700375\n",
      "https://rabota1000.ru/vacancy/99024039\n",
      "https://rabota1000.ru/vacancy/65470905\n",
      "https://rabota1000.ru/vacancy/109746279\n",
      "https://rabota1000.ru/vacancy/113225432\n",
      "https://rabota1000.ru/vacancy/103322800\n",
      "https://rabota1000.ru/vacancy/101825668\n",
      "https://rabota1000.ru/vacancy/94889540\n",
      "https://rabota1000.ru/vacancy/94889541\n",
      "https://rabota1000.ru/vacancy/94889542\n",
      "https://rabota1000.ru/vacancy/94889539\n",
      "https://rabota1000.ru/vacancy/102119614\n",
      "https://rabota1000.ru/vacancy/114030573\n",
      "https://rabota1000.ru/vacancy/104079757\n",
      "https://rabota1000.ru/vacancy/101405084\n",
      "https://rabota1000.ru/vacancy/95385363\n",
      "https://rabota1000.ru/vacancy/108625213\n",
      "https://rabota1000.ru/vacancy/114025918\n",
      "https://rabota1000.ru/vacancy/112922507\n",
      "5 https://rabota1000.ru/vacancy/454188\n",
      "https://rabota1000.ru/vacancy/112021710\n",
      "https://rabota1000.ru/vacancy/109404589\n",
      "https://rabota1000.ru/vacancy/109404588\n",
      "https://rabota1000.ru/vacancy/42507636\n",
      "https://rabota1000.ru/vacancy/25599789\n",
      "https://rabota1000.ru/vacancy/60173299\n",
      "https://rabota1000.ru/vacancy/100733405\n",
      "https://rabota1000.ru/vacancy/99024038\n",
      "https://rabota1000.ru/vacancy/99024037\n",
      "https://rabota1000.ru/vacancy/99255452\n",
      "https://rabota1000.ru/vacancy/114686338\n",
      "https://rabota1000.ru/vacancy/94889538\n",
      "https://rabota1000.ru/vacancy/85030794\n",
      "https://rabota1000.ru/vacancy/113212722\n",
      "https://rabota1000.ru/vacancy/113258362\n",
      "https://rabota1000.ru/vacancy/105985490\n",
      "https://rabota1000.ru/vacancy/111906282\n",
      "https://rabota1000.ru/vacancy/107986402\n",
      "https://rabota1000.ru/vacancy/110170388\n",
      "6 https://rabota1000.ru/vacancy/533485\n",
      "https://rabota1000.ru/vacancy/114725096\n",
      "https://rabota1000.ru/vacancy/112930600\n",
      "https://rabota1000.ru/vacancy/114224156\n",
      "https://rabota1000.ru/vacancy/105557375\n",
      "https://rabota1000.ru/vacancy/110825905\n",
      "https://rabota1000.ru/vacancy/114390608\n",
      "https://rabota1000.ru/vacancy/105362560\n",
      "https://rabota1000.ru/vacancy/105922508\n",
      "https://rabota1000.ru/vacancy/108769259\n",
      "https://rabota1000.ru/vacancy/105331322\n",
      "https://rabota1000.ru/vacancy/110223373\n",
      "https://rabota1000.ru/vacancy/109831875\n",
      "https://rabota1000.ru/vacancy/114398936\n",
      "https://rabota1000.ru/vacancy/104677064\n",
      "https://rabota1000.ru/vacancy/103654986\n",
      "https://rabota1000.ru/vacancy/111248398\n",
      "https://rabota1000.ru/vacancy/108536947\n",
      "https://rabota1000.ru/vacancy/105484654\n",
      "https://rabota1000.ru/vacancy/104596316\n",
      "7 https://rabota1000.ru/vacancy/108616052\n",
      "https://rabota1000.ru/vacancy/108616051\n",
      "https://rabota1000.ru/vacancy/106347104\n",
      "https://rabota1000.ru/vacancy/111902433\n",
      "https://rabota1000.ru/vacancy/97465285\n",
      "https://rabota1000.ru/vacancy/103174822\n",
      "https://rabota1000.ru/vacancy/105454036\n",
      "https://rabota1000.ru/vacancy/103344293\n",
      "https://rabota1000.ru/vacancy/78034702\n",
      "https://rabota1000.ru/vacancy/113201770\n",
      "https://rabota1000.ru/vacancy/104139159\n",
      "https://rabota1000.ru/vacancy/103191712\n",
      "https://rabota1000.ru/vacancy/114206125\n",
      "https://rabota1000.ru/vacancy/88320984\n",
      "https://rabota1000.ru/vacancy/97480461\n",
      "https://rabota1000.ru/vacancy/112367347\n",
      "https://rabota1000.ru/vacancy/90751563\n",
      "https://rabota1000.ru/vacancy/111248291\n",
      "https://rabota1000.ru/vacancy/114027186\n",
      "https://rabota1000.ru/vacancy/105573043\n",
      "8 https://rabota1000.ru/vacancy/103157120\n",
      "https://rabota1000.ru/vacancy/107916751\n",
      "https://rabota1000.ru/vacancy/109399297\n",
      "https://rabota1000.ru/vacancy/105485537\n",
      "https://rabota1000.ru/vacancy/114746523\n",
      "https://rabota1000.ru/vacancy/112328939\n",
      "https://rabota1000.ru/vacancy/93213438\n",
      "https://rabota1000.ru/vacancy/92045790\n",
      "https://rabota1000.ru/vacancy/104584307\n",
      "https://rabota1000.ru/vacancy/109399299\n",
      "https://rabota1000.ru/vacancy/105355796\n",
      "https://rabota1000.ru/vacancy/98985891\n",
      "https://rabota1000.ru/vacancy/108797837\n",
      "https://rabota1000.ru/vacancy/107714052\n",
      "https://rabota1000.ru/vacancy/106774493\n",
      "https://rabota1000.ru/vacancy/105990718\n",
      "https://rabota1000.ru/vacancy/105577309\n",
      "https://rabota1000.ru/vacancy/104579578\n",
      "https://rabota1000.ru/vacancy/109399298\n",
      "https://rabota1000.ru/vacancy/70197392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lapis\\Desktop\\1T_Stagirovka\\rabota1000\\pars_test.ipynb Ячейка 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=208'>209</a>\u001b[0m             dict_writer\u001b[39m.\u001b[39mwriterows(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_resualt)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=211'>212</a>\u001b[0m parser \u001b[39m=\u001b[39m Rabota1000_Parser()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=212'>213</a>\u001b[0m parser\u001b[39m.\u001b[39;49mpars()\n",
      "\u001b[1;32mc:\\Users\\lapis\\Desktop\\1T_Stagirovka\\rabota1000\\pars_test.ipynb Ячейка 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m@click\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mvacancyLinkClickHandler\u001b[39m\u001b[39m'\u001b[39m}):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mprint\u001b[39m(link[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m links \u001b[39m=\u001b[39m [requests\u001b[39m.\u001b[39;49mget(link[\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49murl \u001b[39mfor\u001b[39;49;00m link \u001b[39min\u001b[39;49;00m soup\u001b[39m.\u001b[39;49mfindAll(\u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m'\u001b[39;49m, attrs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39m@click\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mvacancyLinkClickHandler\u001b[39;49m\u001b[39m'\u001b[39;49m})]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m sources \u001b[39m=\u001b[39m [source\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m source \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39mspan\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mtext-sky-600\u001b[39m\u001b[39m'\u001b[39m})]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m links_to_save \u001b[39m=\u001b[39m [[vac_name, link, source] \u001b[39mfor\u001b[39;00m link, source \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(links, sources)]\n",
      "\u001b[1;32mc:\\Users\\lapis\\Desktop\\1T_Stagirovka\\rabota1000\\pars_test.ipynb Ячейка 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m@click\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mvacancyLinkClickHandler\u001b[39m\u001b[39m'\u001b[39m}):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mprint\u001b[39m(link[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m links \u001b[39m=\u001b[39m [requests\u001b[39m.\u001b[39;49mget(link[\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39murl \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m@click\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mvacancyLinkClickHandler\u001b[39m\u001b[39m'\u001b[39m})]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m sources \u001b[39m=\u001b[39m [source\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m source \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39mspan\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mtext-sky-600\u001b[39m\u001b[39m'\u001b[39m})]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lapis/Desktop/1T_Stagirovka/rabota1000/pars_test.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m links_to_save \u001b[39m=\u001b[39m [[vac_name, link, source] \u001b[39mfor\u001b[39;00m link, source \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(links, sources)]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1095\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1096\u001b[0m         (\n\u001b[0;32m   1097\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1102\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1103\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    610\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    612\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m    613\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[0;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[0;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Rabota1000_Parser:\n",
    "    # Класс для парсинга вакансий с ресурса Rabota1000.ru\n",
    "    def __init__(self, city:str='russia'):\n",
    "        self.pre_resualt = []\n",
    "        self.pre_data = []\n",
    "        self.max_page_count = 10\n",
    "        self.basic_url = f'https://rabota1000.ru/{city}/'\n",
    "        self.vac_name_list = []\n",
    "        self.vac_name_list = [\n",
    "            'data+scientist', 'data+science', 'дата+сайентист',\n",
    "            'младший+дата+сайентист', 'стажер+дата+сайентист',\n",
    "            'machine+learning', 'ml', 'ml+engineer',\n",
    "            'инженер+машинного+обучения', 'data+engineering',\n",
    "            'инженер+данных', 'младший+инженер+данных',\n",
    "            'junior+data+analyst', 'junior+data+scientist',\n",
    "            'junior+data+engineer', 'data+analyst',\n",
    "            'data+analytics','аналитик+данных', 'big+data+junior'\n",
    "        ]\n",
    "        \n",
    "        self.ua = FakeUserAgent()\n",
    "        headers = {'user-agent':self.ua.random}\n",
    "\n",
    "    def pars(self):\n",
    "        if not os.path.exists('pars_link.csv'):\n",
    "            with open('pars_link.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "                names = ['vac_name', 'link', 'source', 'vac_id']\n",
    "                file_writer = csv.DictWriter(csv_file, delimiter = \",\", lineterminator=\"\\r\", fieldnames=names)\n",
    "                file_writer.writeheader()\n",
    "\n",
    "            for vac_name in self.vac_name_list:\n",
    "                print(vac_name)\n",
    "                try:\n",
    "                    used_url = self.basic_url + vac_name + \"/\"\n",
    "                    response = requests.get(used_url)\n",
    "                    response.raise_for_status()\n",
    "                    for i in range(1, self.max_page_count+1):\n",
    "                        print(i, end=' ')\n",
    "                        used_url = f'{self.basic_url}{vac_name}?p={i}'\n",
    "                        page = requests.get(used_url)\n",
    "                        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "                        # 20 ссылок на одной странице\n",
    "                        for link in soup.findAll('a', attrs={'@click':'vacancyLinkClickHandler'}):\n",
    "                            print(link['href'])\n",
    "                        links = [requests.get(link['href']).url for link in soup.findAll('a', attrs={'@click':'vacancyLinkClickHandler'})]\n",
    "                        sources = [source.text for source in soup.findAll('span', attrs={'class':'text-sky-600'})]\n",
    "\n",
    "                        links_to_save = [[vac_name, link, source] for link, source in zip(links, sources)]\n",
    "\n",
    "                        with open('pars_link.csv', 'a', newline='', encoding='utf-8') as csv_file:\n",
    "                            writer = csv.writer(csv_file)\n",
    "                            writer.writerows(links_to_save)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                print()\n",
    "        if not os.path.exists('finaly.csv'):\n",
    "            links_for_processing = []\n",
    "            with open('pars_link.csv', 'r', encoding='utf-8') as csv_file:\n",
    "                reader = csv.reader(csv_file)\n",
    "                labels = next(reader, None)\n",
    "                for row in reader:\n",
    "                    links_for_processing.append(dict(zip(labels, row)))\n",
    "\n",
    "            for item in links_for_processing:\n",
    "                if item['source'] == 'hh.ru':\n",
    "                    item['vac_id'] = re.search(re_vacancy_id_hh, item['link']).group(1)\n",
    "                elif item['source'] == 'finder.vc':\n",
    "                    item['vac_id'] = re.search(re_vacancy_id_finder, item['link']).group(1)\n",
    "                elif item['source'] == 'zarplata.ru':\n",
    "                    item['vac_id'] = re.search(re_vacancy_id_zarplata, item['link']).group(1)\n",
    "                else:\n",
    "                    item['vac_id'] = re.search(re_vacancy_id_rabota, item['link']).group(1)\n",
    "\n",
    "            \n",
    "            bar = progressbar.ProgressBar(maxval=len(links_for_processing)).start()\n",
    "            k = 0\n",
    "            for link in links_for_processing:\n",
    "                if link['source'] == 'hh.ru':\n",
    "                    self.pre_resualt.append(self._pars_url_hh(link['vac_id']))\n",
    "                elif link['source'] == 'zarplata.ru':\n",
    "                    self.pre_resualt.append(self._pars_url_zarplata(link['vac_id']))\n",
    "                elif link['source'] == 'finder.vc':\n",
    "                    self.pre_resualt.append(self._pars_url_finder(link['vac_id']))\n",
    "                else:\n",
    "                    self.pre_resualt.append(self._pars_url_other(link['vac_id']))\n",
    "                k += 1\n",
    "                bar.update(k)\n",
    "            \n",
    "            self._save_frame_to_csv()\n",
    "        else:\n",
    "            with open('finaly.csv', 'r', encoding='utf-8') as csv_file:\n",
    "                reader = csv.reader(csv_file)\n",
    "                labels = next(reader, None)\n",
    "                for row in reader:\n",
    "                    self.pre_resualt.append(dict(zip(labels, row)))\n",
    "\n",
    "    def get_vac_name_into_file(self, vac_file_path:str)->list:\n",
    "        vac_name_list = []\n",
    "        with open(vac_file_path, mode='r', encoding=\"utf-8\") as file_vac:\n",
    "            vac_name_list = list(map(lambda x: x.lower().replace('\\n', '').replace(' ','+'), file_vac.readlines()))\n",
    "\n",
    "        return vac_name_list\n",
    "\n",
    "    def _pars_url_hh(self, id:str)->dict:\n",
    "        res = {}\n",
    "        try:\n",
    "            data = requests.get(f'https://api.hh.ru/vacancies/{id}', headers = {'Authorization': f'Bearer {access_token}'}).json()\n",
    "            res['vac_link'] = f'https://hh.ru/vacancy/{id}'                             # Ссылка\n",
    "            res['name'] = data['name']                                                  # Название\n",
    "            res['city'] = data['area']['name']                                          # Город\n",
    "            res['company'] = data['employer']['name']                                   # Назвнание компании публикующей вакансию\n",
    "            res['experience'] = data['experience']['name']                              # Опыт работы (нет замены на jun mid и sin)\n",
    "            res['schedule'] = data['schedule']['name']                                  # Тип работы (офис/удаленка и тд)\n",
    "            res['employment'] = data['employment']['name']                              # График работы\n",
    "            res['skills'] = [item['name'] for item in data['key_skills']]               # Ключевые навыки\n",
    "            res['description'] = re.sub(re_html_tag_remove, '', data['description'])    # Полное описание (html теги не убраны)\n",
    "            if data['salary'] == None: \n",
    "                res['salary'] = 'Договорная'                                            # Если ЗП не указано то пишем договорная\n",
    "            else:\n",
    "                res['salary'] = data['salary']                                          # Если есть то берем как есть\n",
    "            res['time'] = data['published_at']                                          # Дата и время публикации\n",
    "        except Exception as e:\n",
    "            print(f'Not Found {e}')\n",
    "            print(f'https://api.hh.ru/vacancies/{id}')\n",
    "            data = requests.get(f'https://api.hh.ru/vacancies/{id}', headers = {'Authorization': f'Bearer {access_token}'}).json()\n",
    "            print(data)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _pars_url_zarplata(self, id:str)->dict:\n",
    "        res = {}\n",
    "        try:\n",
    "            data = requests.get(f'https://api.zarplata.ru/vacancies/{id}').json()\n",
    "            res['vac_link'] = f'https://www.zarplata.ru/vacancy/card/id{id}'            # Ссылка\n",
    "            res['name'] = data['name']                                                  # Название\n",
    "            res['city'] = data['area']['name']                                          # Город\n",
    "            res['company'] = data['employer']['name']                                   # Назвнание компании публикующей вакансию\n",
    "            res['experience'] = data['experience']['name']                              # Опыт работы (нет замены на jun mid и sin)\n",
    "            res['schedule'] = data['schedule']['name']                                  # Тип работы (офис/удаленка и тд)\n",
    "            res['employment'] = data['employment']['name']                              # График работы\n",
    "            res['skills'] = [item['name'] for item in data['key_skills']]               # Ключевые навыки\n",
    "            res['description'] = re.sub(re_html_tag_remove, '', data['description'])    # Полное описание\n",
    "            if data['salary'] == None: \n",
    "                res['salary'] = 'Договорная'                                            # Если ЗП не указано то пишем договорная\n",
    "            else:\n",
    "                res['salary'] = data['salary']                                          # Если есть то берем как есть\n",
    "            res['time'] = data['published_at']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Not Found {e}')\n",
    "            print(f'https://api.zarplata.ru/vacancies/{id}')\n",
    "            data = requests.get(f'https://api.zarplata.ru/vacancies/{id}').json()\n",
    "            print(data)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _pars_url_other(self, id:str)->dict:\n",
    "        res = {}\n",
    "        soup = BeautifulSoup(requests.get(f'https://rabota1000.ru/vacancy/{id}').text, 'html.parser')\n",
    "        dom = lxml.etree.HTML(str(soup)) \n",
    "        res['vac_link'] = f'https://rabota1000.ru/vacancy/{id}'                                                                                             # Ссылка\n",
    "        res['name'] = dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[1]/div[1]/h2')[0].text.replace('\\n', '').lstrip().rstrip()            # Название\n",
    "        res['city'] = dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[1]/div[3]/p[2]/span')[0].text                                         # Город (НЕТ)\n",
    "        res['company'] = dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[1]/div[3]/p[1]')[0].text.replace('\\n', '').lstrip().rstrip()       # Назвнание компании публикующей вакансию\n",
    "        res['experience'] = ''                                                                                                                              # Опыт работы (нет замены на jun mid и sin)\n",
    "        res['schedule'] = ''                                                                                                                                # Тип работы (офис/удаленка и тд) (НЕТ)\n",
    "        res['employment'] = dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[3]/ul/li[2]/span')[0].text                                      # График работы\n",
    "        res['skills'] = ''                                                                                                                                  # Ключевые навыки\n",
    "        res['description'] = re.sub(re_html_tag_remove, '', dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[4]')[0].text)                                                   # Полное описание (НЕТ)\n",
    "        if len(dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[1]/div[2]/span'))>0:\n",
    "            res['salary'] = dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[1]/div[2]/span')[0].text.replace('\\n', '').lstrip().rstrip()        # ЗП\n",
    "        else:\n",
    "            res['salary'] = 'Договорная'\n",
    "        res['time'] = dom.xpath('/html/body/div[1]/main/div[2]/div/div/div[2]/section[3]/ul/li[1]/span')[0].text.replace('\\n', '').lstrip().rstrip()        # Дата публикации\n",
    "\n",
    "        return res\n",
    "        \n",
    "    def _pars_url_finder(self, id:str)->list:\n",
    "        res = {}\n",
    "        soup = BeautifulSoup(requests.get(f'https://finder.vc/vacancies/{id}').text, 'html.parser')\n",
    "        dom = lxml.etree.HTML(str(soup)) \n",
    "        res['vac_link'] = f'https://finder.vc/vacancies/{id}' # Ссылка\n",
    "        res['name'] = soup.find('h1', attrs={'class':'vacancy-info-header__title'}).text # Название\n",
    "        res['city'] = ''              # Город (НЕТ)\n",
    "        res['company'] = dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[2]/div[1]/div[2]/div/div[1]/a')[0].text        # Назвнание компании публикующей вакансию\n",
    "        res['experience'] = dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[2]/div[3]/div[1]/div[2]/div')[0].text  # Опыт работы (нет замены на jun mid и sin)\n",
    "        res['schedule'] = ''     # Тип работы (офис/удаленка и тд) (НЕТ\n",
    "        res['employment'] = dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[3]/div/div[2]/a')[0].text # График работы\n",
    "        res['skills'] = [li.text for li in dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[3]/div[1]/div[2]/div[1]/ul')[0]]           # Ключевые навыки\n",
    "        res['description'] = ''    # Полное описание (НЕТ)\n",
    "        res['salary'] = dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[2]/div[2]/div[2]/div')[0].text.replace(u'\\xa0', '')\n",
    "\n",
    "        if 'сегодня' in dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[1]')[0].text:\n",
    "            res['time'] = str(date.today())\n",
    "        elif 'вчера' in dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[1]')[0].text:\n",
    "            res['time'] = str(date.today() - timedelta(days=1))\n",
    "        else:\n",
    "            res['time'] = str(date.today() - timedelta(days=int(re.search(r'Опубликована (\\d+)', dom.xpath('/html/body/div[1]/div[2]/div/main/div/div/div[2]/div[1]/div/div/div[1]/div/div[1]')[0].text).group(1))))\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def _save_frame_to_csv(self):\n",
    "        keys = self.pre_resualt[0].keys()\n",
    "\n",
    "        with open('finaly.csv', 'w', newline='', encoding='utf-8') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys, delimiter = \",\", lineterminator=\"\\r\")\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(self.pre_resualt)\n",
    "\n",
    "\n",
    "parser = Rabota1000_Parser()\n",
    "parser.pars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vac_link</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "      <th>schedule</th>\n",
       "      <th>employment</th>\n",
       "      <th>skills</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://hh.ru/vacancy/86788792</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Москва</td>\n",
       "      <td>МегаФон</td>\n",
       "      <td>От 1 года до 3 лет</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>['PyTorch', 'Spark', 'Big Data', 'GAN']</td>\n",
       "      <td>Мы в поисках Middle Data scientist в нашу кома...</td>\n",
       "      <td>Договорная</td>\n",
       "      <td>2023-09-15T16:19:16+0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://hh.ru/vacancy/86597536</td>\n",
       "      <td>Аналитик данных / Data Scientist, Middle, авиа</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Туту.ру</td>\n",
       "      <td>От 3 до 6 лет</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>['Python', 'SQL', 'Data Analysis', 'Математиче...</td>\n",
       "      <td>Привет! Мы в tutu продаём билеты, чтобы отправ...</td>\n",
       "      <td>Договорная</td>\n",
       "      <td>2023-09-12T11:46:39+0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hh.ru/vacancy/84462656</td>\n",
       "      <td>Data Scientist (NLP)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Samokat.tech</td>\n",
       "      <td>От 3 до 6 лет</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>['Python', 'ML', 'Machine Learning', 'Jupyter'...</td>\n",
       "      <td>Для эффективной работы сервисов мы активно исп...</td>\n",
       "      <td>Договорная</td>\n",
       "      <td>2023-10-10T17:07:30+0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://hh.ru/vacancy/86664203</td>\n",
       "      <td>Data scientist (Middle)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>МегаФон</td>\n",
       "      <td>От 1 года до 3 лет</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>['Python', 'SQL', 'Spark', 'Hadoop', 'Pandas',...</td>\n",
       "      <td>Привет, ищем в нашу команду Middle Data scient...</td>\n",
       "      <td>Договорная</td>\n",
       "      <td>2023-09-13T12:48:33+0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://hh.ru/vacancy/86336141</td>\n",
       "      <td>Data Scientist (Распознавание речи)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>АБК</td>\n",
       "      <td>От 3 до 6 лет</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>['RND', 'Python', 'Linux', 'Git', 'SQL', 'PyTo...</td>\n",
       "      <td>Кто мы? Наша компания основана Сбером в 2013 г...</td>\n",
       "      <td>Договорная</td>\n",
       "      <td>2023-09-18T09:01:17+0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         vac_link  \\\n",
       "0  https://hh.ru/vacancy/86788792   \n",
       "1  https://hh.ru/vacancy/86597536   \n",
       "2  https://hh.ru/vacancy/84462656   \n",
       "3  https://hh.ru/vacancy/86664203   \n",
       "4  https://hh.ru/vacancy/86336141   \n",
       "\n",
       "                                             name    city       company  \\\n",
       "0                                  Data scientist  Москва       МегаФон   \n",
       "1  Аналитик данных / Data Scientist, Middle, авиа  Москва       Туту.ру   \n",
       "2                            Data Scientist (NLP)  Москва  Samokat.tech   \n",
       "3                         Data scientist (Middle)  Москва       МегаФон   \n",
       "4             Data Scientist (Распознавание речи)  Москва           АБК   \n",
       "\n",
       "           experience          schedule        employment  \\\n",
       "0  От 1 года до 3 лет  Удаленная работа  Полная занятость   \n",
       "1       От 3 до 6 лет       Полный день  Полная занятость   \n",
       "2       От 3 до 6 лет  Удаленная работа  Полная занятость   \n",
       "3  От 1 года до 3 лет  Удаленная работа  Полная занятость   \n",
       "4       От 3 до 6 лет  Удаленная работа  Полная занятость   \n",
       "\n",
       "                                              skills  \\\n",
       "0            ['PyTorch', 'Spark', 'Big Data', 'GAN']   \n",
       "1  ['Python', 'SQL', 'Data Analysis', 'Математиче...   \n",
       "2  ['Python', 'ML', 'Machine Learning', 'Jupyter'...   \n",
       "3  ['Python', 'SQL', 'Spark', 'Hadoop', 'Pandas',...   \n",
       "4  ['RND', 'Python', 'Linux', 'Git', 'SQL', 'PyTo...   \n",
       "\n",
       "                                         description      salary  \\\n",
       "0  Мы в поисках Middle Data scientist в нашу кома...  Договорная   \n",
       "1  Привет! Мы в tutu продаём билеты, чтобы отправ...  Договорная   \n",
       "2  Для эффективной работы сервисов мы активно исп...  Договорная   \n",
       "3  Привет, ищем в нашу команду Middle Data scient...  Договорная   \n",
       "4  Кто мы? Наша компания основана Сбером в 2013 г...  Договорная   \n",
       "\n",
       "                       time  \n",
       "0  2023-09-15T16:19:16+0300  \n",
       "1  2023-09-12T11:46:39+0300  \n",
       "2  2023-10-10T17:07:30+0300  \n",
       "3  2023-09-13T12:48:33+0300  \n",
       "4  2023-09-18T09:01:17+0300  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"finaly.csv\")  \n",
    "df[['vac_link', 'name', 'city', 'company', 'experience', 'schedule', 'employment', 'skills', 'description', 'salary']] = df[['vac_link', 'name', 'city', 'company', 'experience', 'schedule', 'employment', 'skills', 'description', 'salary']].astype(\"string\")\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
